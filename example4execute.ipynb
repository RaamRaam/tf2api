{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaamRaam/tf2api/blob/master/example4execute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLsFb-tM8Au7"
      },
      "source": [
        "# **TF2 Wrapper functions**\n",
        "\n",
        "## Objective\n",
        "To write simplified *function interfaces* to TF2 capabilities that simplifies Data pipeline, model building, training, evaluating, deploying models\n",
        "\n",
        "___New features in TF2___\n",
        "* Eager Execution by Default\n",
        "* Keras layers and models to manage variables\n",
        "* tf.data.Datasets to stream data\n",
        "* tf.function decorator for graph execution\n",
        "* More on above in https://www.tensorflow.org/guide/effective_tf2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpUFBYbG2Kb3"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhFzNUY0P1P1"
      },
      "source": [
        "print(str(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-CCi03fCMMJ"
      },
      "source": [
        "# Choosing GPU in colab\n",
        "\n",
        "The processor for heavy duty computing\n",
        "\n",
        "__Runtime => Change Runtime Type => GPU__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eggJzyiYWd-"
      },
      "source": [
        "if tf.test.is_gpu_available():\n",
        "  print(tf.test.gpu_device_name())\n",
        "else:\n",
        "  print('No GPU found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVStACgMC2O2"
      },
      "source": [
        "# tf2api Repository\n",
        "\n",
        "TF2 simplifies model building significantly\n",
        "\n",
        "However, the repository attempts to simplify model building process wrapping all complex code behind functions\n",
        "\n",
        "The clone will be available in colab for the session\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khGZ3picPKTJ"
      },
      "source": [
        "# !rm -rf tf2api\n",
        "!git clone https://github.com/RaamRaam/tf2api.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf21-15TGAya"
      },
      "source": [
        "# tf2api interfaces\n",
        "\n",
        "we will be referring tf2api as tf2x through out\n",
        "\n",
        "The datasets will be in __ds__ object.  The object stores all vital information with respect to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSyDeld7S4cC"
      },
      "source": [
        "import tf2api as tf2x\n",
        "from tf2api.tfrecords import ds \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# tf2x=train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa2bqoJlG2EE"
      },
      "source": [
        "# Dataset in TFRecords format\n",
        "\n",
        "* we will be using MNIST dataset for demonstration\n",
        "* The dataset will contain _features_ and _lables_ as dictionary\n",
        "* _SaveTFRecordSet_ function from library will save the dataset in __TFRecords__ format \n",
        "* The saved file will be available for colab session\n",
        "* More on TFRecord format in https://www.tensorflow.org/tutorials/load_data/tfrecord and https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wA0k6HLQNvX"
      },
      "source": [
        "import os\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "class_names = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
        "\n",
        "train_data={}\n",
        "train_data['features']=x_train.astype(float)\n",
        "train_data['lables']=y_train\n",
        "\n",
        "test_data={}\n",
        "test_data['features']=x_test.astype(float)\n",
        "test_data['lables']=y_test\n",
        "\n",
        "path=r'/content'\n",
        "\n",
        "tf2x.SaveTFRecordSet(os.path.join(path, 'mnist_train.tfrecords'),train_data)\n",
        "tf2x.SaveTFRecordSet(os.path.join(path, 'mnist_test.tfrecords'),test_data)\n",
        "tf2x.create_classfile(os.path.join(path, 'classes.txt'),class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrfFUTxSH-Cb"
      },
      "source": [
        "# Dataset object from library\n",
        "\n",
        "* We must instantiate Dataset object with _ds()_\n",
        "* We can read the data from TFRecords file with the help of _ReadTFRecordSet_ funcion into Dataset object\n",
        "* ds_obj.length will give the number of records in the file\n",
        "* ds_obj.columns will give the data stored in the file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06q2XkTCdXMn"
      },
      "source": [
        "train_ds=ds()\n",
        "tffilelist=!ls /content/mnist_train.tfrecords -ltrh\n",
        "# tffilelist=[i.split(' \\'')[-1][:-1] for i in tffilelist]\n",
        "tffilelist=[i.split()[-1] for i in tffilelist]\n",
        "train_ds.ReadTFRecordSet(tffilelist,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK7mjdXeLS58"
      },
      "source": [
        "# train_ds.length\n",
        "\n",
        "# train_ds.columns\n",
        "\n",
        "# for i in train_ds.ds:\n",
        "#   print(i['lables'])\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52i5O5N95xB-"
      },
      "source": [
        "test_ds=ds()\n",
        "tffilelist=!ls /content/mnist_test.tfrecords -ltrh\n",
        "# tffilelist=[i.split(' \\'')[-1][:-1] for i in tffilelist]\n",
        "tffilelist=[i.split()[-1] for i in tffilelist]\n",
        "test_ds.ReadTFRecordSet(tffilelist,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3JqxpX-LavY"
      },
      "source": [
        "# Sampling records from Dataset object\n",
        "\n",
        "* The following code samples records with _FilterTFRecordSet_ function in library\n",
        "* All the functions are available in __tfrecords.py__ file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PQz_MecueW8"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "fig=plt.figure(figsize=(14,14))\n",
        "plt.rcParams['figure.dpi'] = 250\n",
        "plt.subplots_adjust(left=1, bottom=1, right=2, top=4)\n",
        "\n",
        "select=test_ds.FilterTFRecordSet('lables',5)\n",
        "number_of_images=10\n",
        "ctr=1\n",
        "for i in select.ds:\n",
        "  if ctr<=number_of_images:\n",
        "    # print(tf.reshape(i['features'],[28,28]).shape)\n",
        "    fig.add_subplot(number_of_images, 5, ctr)\n",
        "    plt.imshow(tf.reshape(i['features'],[28,28]))\n",
        "    # print(i['lables'].numpy())\n",
        "    ctr=ctr+1\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Ct12MUdmD1"
      },
      "source": [
        "def model():\n",
        "  return tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.02),input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "# model().summary()\n",
        "# keras.utils.plot_model(model(), 'my_first_model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFHCTaZ6AkJ4"
      },
      "source": [
        "a=tf2x.train()\n",
        "a.name='first'\n",
        "a.epochs=10\n",
        "a.batch_size=512\n",
        "a.lr_peak=2\n",
        "a.lr_repeat=3\n",
        "modes=['constant','stepup','stepdown','angledup','angleddown']\n",
        "a.lr_mode=modes[0]\n",
        "a.log_path='logs'\n",
        "a.model=model\n",
        "# a.lossfunction=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# a.optimizer=tf.keras.optimizers.SGD\n",
        "a.call(train_ds,test_ds)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMvEnSK7krim"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qn47OPfIDYP"
      },
      "source": [
        "a.batch_size=1024\n",
        "a.epochs=5\n",
        "a.call(train_ds,test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T19GsK2vRaM3"
      },
      "source": [
        "!mkdir models\n",
        "!mkdir models/first\n",
        "a.save('models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUi50vbRZTx"
      },
      "source": [
        "d=tf2x.train()\n",
        "d.name='first'\n",
        "d.load('models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnmX27uhrpnj"
      },
      "source": [
        "b=tf2x.train()\n",
        "b.name='first'\n",
        "b.load('models')\n",
        "b.name='second'\n",
        "!mkdir models/second\n",
        "b.save('models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTKrZKojLptX"
      },
      "source": [
        "b.call(train_ds,test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVC3fy_fiG-v",
        "outputId": "ebf96355-bf7d-406b-a229-722707135d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "actuals, predictions=a.evaluate(train_ds.ds)\n",
        "act_pred=[(i,actuals[i],predictions[i].index(max(predictions[i]))) for i in range(len(actuals))]\n",
        "'Train accuray is ' + str(100*(1-len([act_pred[i] for i in range(len(act_pred)) if act_pred[i][1]!=act_pred[i][2]])/60000))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Train accuray is 9.871666666666668'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2J6lld0jBB5",
        "outputId": "e0d3aca8-ea25-46fa-d300-a7561a42f185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "actuals, predictions=a.evaluate(test_ds.ds)\n",
        "act_pred=[(i,actuals[i],predictions[i].index(max(predictions[i]))) for i in range(len(actuals))]\n",
        "'Test accuray is ' + str(100*(1-len([act_pred[i] for i in range(len(act_pred)) if act_pred[i][1]!=act_pred[i][2]])/10000))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Test accuray is 9.799999999999997'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR_-NS3IAkCo"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHAoL9qtjuxh"
      },
      "source": [
        "def model():\n",
        "  inputs = keras.Input(shape=(28,28,1), name='Inputs')\n",
        "  x = layers.Conv2D(filters=32,kernel_size=(3,3), activation='relu', name='Conv_1')(inputs)\n",
        "  x = layers.MaxPooling2D()(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  x = layers.Dense(64,activation='relu')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  outputs = layers.Dense(10,activation='softmax')(x)\n",
        "  return keras.Model(inputs=inputs, outputs=outputs)\n",
        "model().summary()\n",
        "keras.utils.plot_model(model(), 'my_first_model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJRjgiNtyu1"
      },
      "source": [
        "def model():\n",
        "  return tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.02),input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "model().summary()\n",
        "keras.utils.plot_model(model(), 'my_first_model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAtRcQBCu2GQ"
      },
      "source": [
        "\n",
        "def make_model():\n",
        "  with tf.name_scope('Input'):\n",
        "    inputs = keras.Input(shape=(28,28,1), name='Inputs')\n",
        "\n",
        "  with tf.name_scope('Block1'):\n",
        "    x = layers.Conv2D(filters=32,kernel_size=(3,3), activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.02),use_bias=False, name='B1_3x3')(inputs)\n",
        "    x = layers.BatchNormalization(name='B1_BN')(x)\n",
        "    x = layers.MaxPooling2D(name='B1_MP')(x)\n",
        "\n",
        "  with tf.name_scope('Block2'):  \n",
        "    x = layers.Conv2D(filters=64,kernel_size=(3,3), activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.02),use_bias=False, name='B2_3x3')(x)\n",
        "    x = layers.BatchNormalization(name='B2_BN')(x)\n",
        "    x = layers.MaxPooling2D(name='B2_MP')(x)\n",
        "\n",
        "  with tf.name_scope('Block3'):  \n",
        "    x = layers.Conv2D(filters=128,kernel_size=(3,3), activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.02),use_bias=False, name='B3_3x3')(x)\n",
        "    x = layers.BatchNormalization(name='B3_BN')(x)\n",
        "\n",
        "  with tf.name_scope('Output'):\n",
        "    x = layers.Conv2D(filters=10,kernel_size=(3,3), activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.02),use_bias=False, name='B4_3x3')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    outputs = layers.Activation('softmax')(x)\n",
        "  return keras.Model(inputs=inputs, outputs=outputs)\n",
        "model().summary()\n",
        "keras.utils.plot_model(model(), 'my_first_model.png', show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1dlroMRrusv"
      },
      "source": [
        "tf.saved_model.save(model(),\"/content/drive/My Drive/tf2apis/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIOxIolgr5SR"
      },
      "source": [
        "!saved_model_cli show --dir \"/content/drive/My Drive/tf2apis/\" --tag_set serve --signature_def serving_default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALJP7m_8r_WB"
      },
      "source": [
        "loaded = tf.saved_model.load(\"/content/drive/My Drive/tf2apis/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iGYjVnNuTA2",
        "outputId": "8d8fc8f1-014e-4dd5-ebfe-0c723ead5680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['serving_default']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0PBDUdjsEpj"
      },
      "source": [
        "infer = loaded.signatures[\"serving_default\"]\n",
        "\n",
        "for i in test_ds.ds:\n",
        "    ftr=tf.reshape(i['features'],[1,28,28,1])\n",
        "    pred=infer(tf.cast(ftr,tf.float16))\n",
        "    pred_list=list(pred.values())[0].numpy()[0]\n",
        "    print(pred_list)\n",
        "    print('Actual:',i['lables'].numpy(), '\\t Predicted:',tf.math.argmax(pred_list).numpy())\n",
        "    plt.imshow(tf.reshape(i['features'],[28,28]))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}